##渲染引擎
渲染引擎的职责是，恩。。渲染，意味着在浏览器窗口上展示请求的内容。
默认情况下渲染引擎能展示HTML、XML文件和图片。通过插件（浏览器拓展）也可以展示其他类型。一个例子是通过PDF预览插件展示PDF文件。我们会在另外的章节讨论插件和拓展。在本章节我们专注于通过css样式控制来展示的html和图片。

###渲染引擎
我们提及的浏览器-Firefox、Chrome、Safari是基于两种渲染引擎的，Firefox使用`Fecko` - 火狐自家的渲染器。Safari和Chrome都是使用`webkit`.webkit作为一个开源的渲染引擎，用在Linux平台，也被苹果公司修改使用在Mac和windows上。查看更多信息 http://webkit.org/。

###主要的流程
渲染引擎开始于得到请求文档的内容，&&&this will usually be done in 8k chunks。

自那以后，下面这幅图片就是渲染引擎的基础工作流。
![flow](../images/flow.png)

- 解析HTML去构建DOM树
- 渲染树构建
- 渲染树布局
- 绘制渲染树

渲染引擎开始解析得到的HTML文档，把tags标志&&&转变为DOM节点挂在一颗叫`内容树content tree`&&&上。这个过程会解析样式的信息，包括外加的css文件和内嵌的style属性。样式的信息跟html中视觉的指令合起来用来创建另一颗树-
`render tree 渲染树` &&&

render tree渲染树包含了一系列带着视觉上属性（颜色、大小）的长方块。这些长方块按顺序被展示在屏幕上。

渲染树构建好以后就进入`布局layout`阶段了。这意味着该给每个节点设置显示在屏幕上的正确坐标了。下一个阶段是`painting 绘制`。渲染树render tree将被遍历然后每个机电会通过UI backend layer绘制在屏幕上。

理解这些过程是很缓和逐渐的是很重要的，为了更好的用户体验，渲染引擎rendering engine 会尽可能快的讲内容展示在屏幕上，它不会等待所有的HTML都被解析完才去构建渲染树和布局，一部分内容会先被解析和展示，而这个过程（上述的1234）会一直持续，随着源源不断来自网络的内容。

![webkit flow](../images/webkitflow.png)
![webkit flow](../images/Geokoflow.jpg)

从上面的两幅图比较就可以看出`webkit`跟`Geoko`有一些术语上的区别，整个流程基本上是一致的。Geoko把样式格式化后的元素的tree定义为 - `Frame tree 结构树`，每一个元素是一个结构frame ，webkit使用render tree 渲染树的术语，渲染树包含一系列render对象。webkit使用`layout布局`描述元素的位置定位，而Geoko称这为Reflow。`Attachment`是一个webkit术语用来描述结合DOM节点DOM nodes和样式信息去生成rendertree渲染树。一个小的非语义上的不同是Geoko有一个在HTML跟DOMtree之间额外的层-`content sink`,这是个工厂用来制造dom元素。我们会详细的讲解每个过程。

###解析 Parsing
parsing解析在渲染引擎中是个非常中要的过程，我们会深挖一点，我们先看点简单的解析parsing介绍。

解析文档意味着把这个文档解释为一些说的通的结构，一种代码能读得懂可以用的结构。解析的结果通常是展示文档结构的nodes节点构成的树。这被称为
`解析树parse tree`或者`句法分析树 syntax tree`。

例子：解析 表达式 `2 + 3 -1` 会返回这个树
![math expression tree node](../images/mathnode.png)

**语法**</br>
解析是以文档遵守的句法规则为基础的，这些规则是这个文档的语言或格式。任何一种可以解析的格式必须确定的包含词汇和句法分析的语法。这被称为 `context free grammar`&&& 。人类语言不是这样一种语言，所以不能被传统的解析技术解析。\

**分析器 Parser ** -词法分析程序的结合</br>
解析可以被拆解成两个副进程。
- 词汇的分析 lexical analysis
- 句法的分析 syntax analysis

词汇分析是一个拆解内容变成`token`符号的过程。`tokens`是语言的词汇，合法的一些小块的集合&&&，在人类语言中这包含了所有出现在字典中的单词。
句法分析由语言句法规则应用。

分析器通常将工作分成两个组件，`lexer 有时候也叫tokenizer 词汇分析程序` 负责打碎内容变成合法的`tokens`，`paser 句法分析程序`负责根据语言句法规则分析文档结构并把文档结构解析成`parse tree解析树`。`lexer`知道怎么除去不相干的东西好比空格跟回车。

![webkit flow](../images/paser.png)

解析的过程是迭代的&&&iterative，解析器（parser）总是会向词汇分析器（lexer）要新的token，然后尽力根据句法规则去匹配，如果匹配了，一个相等于token的node节点会被加到parsetree中，然后解析器parser会迭代下一个token。
如果没有语法规则被匹配到，parser会把token存到本地，and keep asking for tokens until a rule matching all the internally stored tokens is found&&&，如果没有句法规则被找到那么parser会发起一个意外提示，这意味着文档是不合法的并且包含了句法上的错误。

**翻译**</br>
在大多数情况下，parse tree不是最终的产物，解析被用于翻译，把输入的文档转换成另外一种形式。好比汇编，编译器把源代码编译成机器读的懂的代码。首先把输入的文档解析成parse
tree，然后编译成机器读得懂的代码文档。
![webkit flow](../images/compilation.png)


**解析的一个例子**</br>
